{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3615583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sample                                               Text           Label\n",
      "1     10087  TRUTH BY TEXAS 2019 REPUBLICAN PRESIDENT DONAL...     hate speech\n",
      "2     10113  Putin stressing tf out after hearing that some...     hate speech\n",
      "3     10203  Ip Interference in Ukraine move would lead to ...  no hate speech\n",
      "4     10256  9:32 Carolina Forward Thread @ForwardCarolina ...  no hate speech\n",
      "5     10270  THAT'S NOT WHAT 'FUCK PUTIN' MEANS! SEE? EVERY...     hate speech\n",
      "...     ...                                                ...             ...\n",
      "4039  99632  PROTESTORS AROUND THE WORLD RALLY IN SUPPORT O...  no hate speech\n",
      "4040  99658  RT LIVE Q 3 Mar, 2022 08:31 / Home / Russia & ...  no hate speech\n",
      "4041  99773  raging_eve Costa Mesa couple barely escape Ukr...  no hate speech\n",
      "4042  99882  Sign in Contribute The. Guardian For 200 years...  no hate speech\n",
      "4043  99927  Rob Lee @RALee85 Colonel Alexey Gorobets, the ...  no hate speech\n",
      "\n",
      "[4043 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate_stA_train = pd.read_csv(\".\\hate_stA_train.csv\")\n",
    "stA_eval = pd.read_csv(\".\\stA_eval.csv\")\n",
    "stA_test = pd.read_csv(\".\\stA_test.csv\")\n",
    "eval_subtaskA = pd.read_csv(\".\\eval_subtaskA.csv\")\n",
    "nohate_stA_train = pd.read_csv(\".\\put.csv\")\n",
    "\n",
    "problematic_indices_eval = [\n",
    "    39391,\n",
    "48843,\n",
    "94515,\n",
    "81181,\n",
    "69034,\n",
    "47368,\n",
    "29455,\n",
    "56174,\n",
    "57069,\n",
    "74368,\n",
    "67470,\n",
    "73193,\n",
    "50784,\n",
    "66268,\n",
    "84383,\n",
    "98442,\n",
    "99385\n",
    "]\n",
    "\n",
    "def labeler(sample_id, df):\n",
    "    for column, row in df.iterrows():\n",
    "        if str(row['index']) == str(sample_id):\n",
    "            a = int(row['Label'])\n",
    "            if a == 1:\n",
    "                return 'hate speech'\n",
    "            else:\n",
    "                return 'no hate speech'\n",
    "    print(\"Function failed\")\n",
    "\n",
    "training_data = pd.DataFrame(columns=['Sample', 'Text', 'Label'])\n",
    "hate = 'hate speech' #1\n",
    "no_hate = 'no hate speech' #0\n",
    "count = 1\n",
    "for column, row in stA_eval.iterrows():\n",
    "    sample_id = row['filename'].replace(\"/content/drive/MyDrive/CASE2023_Task4/CASE2023_TASK4_EvalData/subtaskA/\",\"\").replace(\".jpg\",\"\")\n",
    "    sample_id_new = sample_id\n",
    "    if int(sample_id) in problematic_indices_eval:\n",
    "        sample_id_new = sample_id+\"(1)\"\n",
    "    sample_text = row['text']\n",
    "    training_data.loc[count] = [sample_id_new, sample_text, labeler(sample_id, eval_subtaskA)]\n",
    "    count+=1\n",
    "for column, row in hate_stA_train.iterrows():\n",
    "    sample_id = row['filename'].replace(\"/content/drive/MyDrive/CASE2023_Task4/CASE2023_TASK4_TrainData/subTaskA/Hate Speech/\",\"\").replace(\".jpg\",\"\")\n",
    "    sample_text = row['text']\n",
    "    training_data.loc[count] = [sample_id, sample_text, hate]\n",
    "    count+=1\n",
    "for column, row in nohate_stA_train.iterrows():\n",
    "    sample_id = row['filename'].replace(\"/content/drive/MyDrive/CASE2023_Task4/CASE2023_TASK4_TrainData/subTaskA/No Hate Speech/\",\"\").replace(\".jpg\",\"\")\n",
    "    sample_text = row['text']\n",
    "    training_data.loc[count] = [sample_id, sample_text, no_hate]\n",
    "    count+=1\n",
    "    \n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb5bf8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sample                                               Text\n",
      "1    10113    When you keep all the good rations for yourself\n",
      "2    10165  Media 9:28 1 Tucker Carlson, downplaying Russi...\n",
      "3    10287  Andreeva Bay nuclear waste storage Bolshaya Lo...\n",
      "4    10443  So many electricians in the Ukraine but no ele...\n",
      "5    10532  Daily Mail MORE STORIES Q Russia has fired 'ab...\n",
      "..     ...                                                ...\n",
      "439  99353   UKRAINIAN RESISTANCE TO RUSSIA imgflip.com A30 $\n",
      "440  99743  Patricia Arquette @PattyArquette Well for Lord...\n",
      "441  99744  4:19 1 Amazon's response to the situation in U...\n",
      "442  99764  Fox News just asked Trump what he'd do differe...\n",
      "443  99828  ALL I SAID WAS... NO CHANCE OF WAR IN UKRAINE ...\n",
      "\n",
      "[443 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.DataFrame(columns=['Sample', 'Text'])\n",
    "count = 1\n",
    "for column, row in stA_test.iterrows():\n",
    "    sample_id = row['filename'].replace(\"/content/drive/MyDrive/CASE2023_Task4/CASE2023_TASK4_TestData/subtaskA/\",\"\").replace(\".jpg\",\"\")\n",
    "    sample_text = row['text']\n",
    "    test_data.loc[count] = [sample_id, sample_text]\n",
    "    count+=1\n",
    "    \n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b74ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv(\"training_df.csv\")\n",
    "test_data.to_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38799d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate speech       2185\n",
      "no hate speech    1858\n",
      "Name: Label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def harry_plotter(df,string, strang):\n",
    "    frequencies = df[string].value_counts()\n",
    "    print(frequencies)\n",
    "    ax = frequencies.plot(kind='bar')\n",
    "    ax.set_xlabel('Polarity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(strang)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "    \n",
    "harry_plotter(training_data, \"Label\", \"Hate vs NoHate in training set\")\n",
    "#harry_plotter(test_data, \"Label\", \"Hate vs NoHate in test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fa47ed",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a2e73a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.8 GiB for an array with shape (32340, 128, 128, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 80>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m         augmented_labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Convert augmented images and labels to NumPy arrays\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m augmented_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m augmented_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(augmented_labels)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Concatenate original and augmented images\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.8 GiB for an array with shape (32340, 128, 128, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Embedding, Conv1D, Input, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv2D, Conv1D, Flatten, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "max_features = 20000\n",
    "embedding_dim = 32\n",
    "sequence_length = 40\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "image_channels = 3\n",
    "\n",
    "# Assuming you have a pandas DataFrame with 'text', 'label', and 'sample' columns for training and test sets\n",
    "train_df = training_data\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_df['Text'])\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['Text'])\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "train_data_text = pad_sequences(train_sequences, maxlen=sequence_length)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = pd.get_dummies(train_df['Label']).values\n",
    "\n",
    "# Load and preprocess the image data\n",
    "def load_image(sample_id):\n",
    "    image_path = f'./training_img/{sample_id}.jpg'\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((image_width, image_height))\n",
    "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "    return image_array\n",
    "\n",
    "train_data_image = np.array([load_image(sample_id) for sample_id in train_df['Sample']])\n",
    "\n",
    "# Split the training set into train and validation sets\n",
    "train_data_text, val_data_text, train_data_image, val_data_image, train_labels, val_labels = train_test_split(\n",
    "    train_data_text, train_data_image, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Data augmentation for images\n",
    "image_data_generator = ImageDataGenerator(\n",
    "    rotation_range=10,  # Rotate the image randomly by a maximum of 10 degrees\n",
    "    width_shift_range=0.1,  # Shift the image horizontally by a maximum of 10% of the width\n",
    "    height_shift_range=0.1,  # Shift the image vertically by a maximum of 10% of the height\n",
    "    shear_range=0.1,  # Apply shear transformation with a maximum of 10% intensity\n",
    "    zoom_range=0.1,  # Zoom into the image by a maximum of 10%\n",
    "    horizontal_flip=True  # Flip the image horizontally randomly\n",
    ")\n",
    "\n",
    "\n",
    "# List to store augmented images\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "# Apply data augmentation to each image sample\n",
    "for image_array, label in zip(train_data_image, train_labels):\n",
    "    for _ in range(10):\n",
    "        augmented_images.append(image_data_generator.random_transform(image_array))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "# Convert augmented images and labels to NumPy arrays\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "# Concatenate original and augmented images\n",
    "train_data_image = np.concatenate([train_data_image, augmented_images], axis=0)\n",
    "train_labels = np.concatenate([train_labels, augmented_labels], axis=0)\n",
    "\n",
    "# Process text input\n",
    "input_text = Input(shape=(sequence_length,))\n",
    "embedding = Embedding(max_features + 1, embedding_dim, input_length=sequence_length,\n",
    "                      embeddings_regularizer=regularizers.l2(0.0005))(input_text)\n",
    "conv_text = Conv1D(128, 3, activation='relu', kernel_regularizer=regularizers.l2(0.0005),\n",
    "                   bias_regularizer=regularizers.l2(0.0005))(embedding)\n",
    "flatten_text = Flatten()(conv_text)\n",
    "\n",
    "# Process image input\n",
    "input_image = Input(shape=(image_height, image_width, image_channels))\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu')(input_image)\n",
    "maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu')(maxpool1)\n",
    "maxpool2 = MaxPooling2D((2, 2))(conv2)\n",
    "flatten_image = Flatten()(maxpool2)\n",
    "\n",
    "# Concatenate image and text features\n",
    "concatenated = concatenate([flatten_image, flatten_text])\n",
    "\n",
    "# Batch normalization\n",
    "batch_norm = BatchNormalization()(concatenated)\n",
    "\n",
    "# Dense layers for classification\n",
    "dense1 = Dense(32, activation='relu',\n",
    "               kernel_regularizer=regularizers.l2(0.001),\n",
    "               bias_regularizer=regularizers.l2(0.001))(batch_norm)\n",
    "dropout_dense = Dropout(0.5)(dense1)\n",
    "output = Dense(2, activation='sigmoid',\n",
    "               kernel_regularizer=regularizers.l2(0.001),\n",
    "               bias_regularizer=regularizers.l2(0.001))(dropout_dense)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input_image, input_text], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='Nadam',\n",
    "              metrics=[\"CategoricalAccuracy\"])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "epochs = 5\n",
    "history = model.fit([train_data_image, train_data_text], train_labels,\n",
    "                    validation_data=([val_data_image, val_data_text], val_labels),\n",
    "                    epochs=epochs, batch_size=32)\n",
    "\n",
    "# Calculate F1 score on the training set\n",
    "train_predictions = model.predict([train_data_image, train_data_text])\n",
    "train_predictions = np.argmax(train_predictions, axis=1)\n",
    "train_true_labels = np.argmax(train_labels, axis=1)\n",
    "train_f1 = f1_score(train_true_labels, train_predictions, average='macro')\n",
    "print(f\"Train F1 score: {train_f1}\")\n",
    "\n",
    "# Extract the training loss and validation loss from the history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot the training loss and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, epochs+1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs+1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139ab2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "633ec467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 19s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image data\n",
    "def load_image_test(sample_id):\n",
    "    image_path = f'./test_img/{sample_id}.jpg'\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((image_width, image_height))\n",
    "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "    return image_array\n",
    "\n",
    "# Assuming you have a pandas DataFrame with 'Text' column for the test set\n",
    "test_df = test_data\n",
    "\n",
    "# Tokenize the text data\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['Text'])\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "test_data_text = pad_sequences(test_sequences, maxlen=sequence_length)\n",
    "\n",
    "# Process image input\n",
    "test_data_image = np.array([load_image_test(sample_id) for sample_id in test_df['Sample']])\n",
    "\n",
    "# Make predictions with both text and image data\n",
    "test_predictions = model.predict([test_data_image, test_data_text])\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "predictions_dict = {sample_id: prediction for sample_id, prediction in zip(test_df['Sample'], test_predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35043942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10113': 0, '10165': 1, '10287': 1, '10443': 0, '10532': 0, '10708': 0, '10760': 1, '11066': 0, '11105': 0, '11224': 1, '11531': 0, '11607': 0, '12073': 1, '12129': 1, '12207': 0, '12515': 0, '12539': 0, '12641': 0, '12733': 1, '12799': 0, '12847': 0, '12886': 1, '12947': 0, '13300': 1, '13593': 1, '13740': 1, '14208': 0, '14269': 1, '14408': 0, '14445': 1, '14828': 1, '14891': 0, '15022': 1, '15256': 0, '15673': 0, '15873': 0, '16114': 0, '16173': 1, '16478': 1, '16514': 1, '16751': 0, '17024': 1, '17078': 0, '17223': 0, '17516': 1, '17590': 0, '17700': 0, '17930': 1, '18381': 0, '18382': 0, '18797': 0, '19000': 1, '19054': 1, '19344': 1, '19438': 1, '19499': 1, '19999': 1, '20095': 0, '20113': 1, '20425': 0, '20496': 1, '20534': 1, '20586': 0, '21069': 1, '21300': 0, '21529': 0, '21659': 0, '22011': 0, '22155': 1, '22171': 0, '22186': 0, '22700': 0, '22764': 0, '22798': 1, '22935': 1, '23204': 0, '23244': 0, '23635': 0, '23784': 0, '24189': 1, '24619': 0, '24639': 0, '24668': 0, '24831': 1, '25159': 0, '25271': 1, '25319': 1, '25432': 0, '26225': 0, '26930': 0, '27391': 0, '27797': 0, '28024': 1, '28215': 1, '28395': 1, '28757': 1, '29545': 0, '29962': 1, '30096': 0, '30517': 0, '30602': 0, '31017': 0, '31173': 0, '31236': 1, '31240': 1, '31272': 0, '31333': 0, '31565': 0, '31838': 0, '31862': 0, '32079': 0, '32111': 0, '32492': 1, '32666': 0, '32698': 0, '32722': 1, '33227': 1, '33421': 0, '33660': 1, '33702': 0, '33715': 0, '33769': 1, '34093': 0, '34101': 0, '34339': 1, '34542': 0, '34628': 1, '34846': 0, '34950': 1, '35083': 1, '35106': 0, '35215': 0, '35237': 1, '35489': 0, '35531': 0, '35727': 0, '35885': 0, '35992': 0, '36419': 0, '36577': 0, '36696': 0, '36709': 1, '36802': 0, '36817': 0, '36838': 1, '37202': 0, '37299': 1, '37302': 1, '37475': 1, '37961': 0, '38605': 0, '39301': 1, '39393': 0, '39563': 0, '40223': 0, '40439': 0, '40491': 1, '41224': 1, '41341': 0, '41406': 0, '41783': 0, '41809': 0, '42309': 0, '42719': 0, '42786': 1, '43091': 1, '43322': 1, '43559': 0, '43640': 0, '44977': 0, '45074': 0, '45220': 0, '45940': 0, '45962': 0, '46144': 0, '46250': 1, '46330': 0, '46716': 0, '46856': 0, '47054': 0, '47181': 1, '47215': 0, '47303': 1, '47809': 0, '47904': 0, '47932': 0, '48187': 1, '48280': 1, '48285': 0, '48300': 1, '48368': 0, '49003': 0, '49022': 1, '49059': 0, '49225': 0, '50126': 0, '50141': 0, '50324': 1, '50530': 1, '50780': 0, '50787': 1, '50808': 1, '51168': 0, '51302': 1, '51378': 1, '51408': 0, '51455': 0, '51462': 1, '51618': 1, '51936': 0, '52137': 0, '52153': 1, '52209': 1, '52627': 1, '52907': 1, '52961': 0, '52971': 1, '52972': 1, '53158': 0, '53426': 0, '53430': 1, '53721': 0, '53814': 0, '53861': 1, '53867': 1, '54422': 0, '54867': 0, '54924': 0, '54933': 1, '55000': 1, '55082': 0, '55384': 1, '56302': 0, '56499': 0, '56560': 0, '56977': 0, '57072': 0, '57408': 0, '57755': 1, '57838': 0, '57977': 1, '58075': 0, '58178': 0, '58218': 0, '58231': 0, '58452': 0, '58497': 0, '58543': 1, '58701': 0, '59119': 1, '59253': 0, '59573': 1, '59695': 0, '59930': 0, '59947': 1, '60153': 1, '60188': 0, '60384': 1, '60433': 1, '60686': 0, '60975': 1, '61072': 0, '61649': 0, '61814': 0, '62008': 1, '62049': 0, '62125': 1, '62168': 1, '62424': 1, '62481': 0, '62703': 0, '62826': 0, '62872': 0, '62937': 1, '63067': 0, '64882': 0, '65115': 0, '65137': 0, '65153': 1, '65603': 0, '66113': 1, '66287': 0, '66569': 0, '66699': 1, '66844': 0, '67523': 0, '67528': 1, '67929': 0, '67972': 1, '68161': 1, '68180': 1, '68213': 1, '68341': 0, '68947': 0, '69093': 1, '69159': 0, '69513': 0, '69966': 1, '70016': 0, '70215': 0, '70652': 1, '70896': 0, '71082': 0, '71122': 0, '71267': 1, '71498': 1, '71620': 1, '72082': 0, '72168': 0, '72345': 1, '73073': 0, '73214': 1, '73361': 1, '73454': 1, '73961': 0, '74279': 0, '74337': 0, '74583': 1, '74723': 0, '74982': 1, '75108': 0, '75278': 0, '75316': 0, '75493': 1, '75494': 1, '75567': 0, '75574': 0, '75718': 0, '75917': 0, '75958': 1, '76211': 1, '77014': 0, '77192': 0, '77277': 0, '77520': 1, '77666': 1, '77720': 0, '78214': 0, '78737': 0, '78894': 0, '78955': 1, '79275': 0, '79496': 0, '79683': 0, '79942': 0, '79975': 1, '80320': 0, '80343': 0, '80572': 0, '80780': 1, '80882': 1, '81797': 0, '82007': 1, '82114': 0, '82402': 0, '82792': 0, '82806': 0, '83116': 0, '83126': 0, '83273': 0, '83498': 1, '83662': 1, '83915': 0, '83966': 0, '84253': 1, '84324': 0, '84640': 0, '84780': 1, '85178': 1, '85261': 0, '85269': 0, '85387': 0, '85500': 0, '85513': 1, '85518': 0, '85902': 1, '86395': 0, '86446': 1, '86750': 1, '87054': 0, '87381': 0, '87449': 1, '87698': 1, '87708': 0, '87927': 0, '88179': 1, '88844': 1, '88916': 0, '89281': 0, '89306': 0, '89311': 0, '89504': 1, '89541': 1, '89938': 0, '90297': 0, '90657': 1, '90722': 0, '91212': 0, '91222': 1, '91370': 0, '91604': 0, '91863': 0, '92097': 0, '92300': 1, '92343': 1, '92391': 1, '92568': 0, '93155': 0, '93226': 0, '93790': 1, '93817': 0, '94175': 0, '94308': 1, '94332': 1, '94492': 0, '94567': 0, '95476': 0, '95570': 0, '95700': 1, '96004': 0, '96038': 0, '96160': 0, '96925': 0, '97357': 0, '97386': 0, '97423': 0, '97555': 1, '97572': 0, '97575': 0, '97695': 0, '97732': 0, '97832': 0, '98063': 0, '98203': 0, '98286': 1, '98934': 0, '99118': 1, '99164': 1, '99353': 0, '99743': 0, '99744': 0, '99764': 0, '99828': 0}\n"
     ]
    }
   ],
   "source": [
    "print(predictions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15e66127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the frequencies of 0s and 1s in the predictions dictionary\n",
    "freq_0 = sum(value == 0 for value in predictions_dict.values())\n",
    "freq_1 = sum(value == 1 for value in predictions_dict.values())\n",
    "\n",
    "# Plot the frequencies\n",
    "labels = ['0', '1']\n",
    "frequencies = [freq_0, freq_1]\n",
    "\n",
    "plt.bar(labels, frequencies)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequencies of Class 0 and Class 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a6c6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [int(mamada) for mamada in list(predictions_dict.keys())]\n",
    "no_sorted = indexes\n",
    "indexes.sort()\n",
    "\n",
    "for i in range(len(no_sorted)):\n",
    "    if no_sorted[i] == indexes[i]:\n",
    "        ola = 0\n",
    "    else:\n",
    "        print(\"FEO\")\n",
    "\n",
    "predictions_dict_sorted = {}\n",
    "for index in indexes:\n",
    "    predictions_dict_sorted[str(index)] = predictions_dict[str(index)]\n",
    "    \n",
    "index_list = list(predictions_dict_sorted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28a8b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jason = open('submission.json', 'w')\n",
    "for i in range(len(index_list)-1):\n",
    "    jason.write('{\"index\": '+ str(index_list[i])+ ', \"prediction\": '+ str(predictions_dict_sorted[index_list[i]])+ \"}\")\n",
    "    jason.write('\\n')\n",
    "jason.write('{\"index\": '+ str(index_list[-1])+ ', \"prediction\": '+ str(predictions_dict_sorted[index_list[-1]])+ \"}\")\n",
    "jason.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45f20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trampitas por si son necesarias:\n",
    "\n",
    "import re\n",
    "\n",
    "jason = open('submission.json', 'r')\n",
    "lineas = jason.readlines()\n",
    "jason.close()\n",
    "\n",
    "leneas = []\n",
    "for liña in lineas:\n",
    "    lañea = liña.split(\",\")\n",
    "    leñea = lañea[0]+\",\" + re.sub(r'([01])', lambda m: '0' if m.group(1) == '1' else '1', lañea[1])\n",
    "    leneas.append(leñea)\n",
    "    \n",
    "    \n",
    "jeson = open('submission.json', 'w')\n",
    "for i in range(len(leneas)-1):\n",
    "    jeson.write(leneas[i])\n",
    "    #jeson.write('\\n')\n",
    "jeson.write(leneas[-1])\n",
    "jeson.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
